{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights Loading\n",
    "\n",
    "Choose your path and load the .pkl file with weights matrices. Also choose the name for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20)\n",
      "(20,)\n",
      "(20, 20)\n",
      "(20,)\n",
      "(20, 16)\n",
      "(16,)\n",
      "(16, 7)\n",
      "(7,)\n",
      "1095 total weights\n"
     ]
    }
   ],
   "source": [
    "# load weights\n",
    "pathToWeights = r\"C:\\Users\\Theodore\\Dropbox\\ExampleData\\Opt_rmsprop__Dro_0.0__Num_20_20_16__Wei_0_pruned_wts.pkl\"\n",
    "# Choose the suffix of your data name. Default are FeedforwardNN. This name string will be added after it.\n",
    "name = ''\n",
    "\n",
    "# read in weight data\n",
    "wts =  pickle.load(open(pathToWeights, 'rb'))\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "max_width = 0\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "    max_width = max(max_width, wts[ii].shape[0])\n",
    "\n",
    "# print total number of weights (including biases)\n",
    "print(np.sum(wtLengths), \"total weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify upper limit for maximal layer size\n",
    "# This is converting the number to a power of 10, making it convenient for node indexing\n",
    "MaxSize = int(10**np.ceil(np.log(max_width)/np.log(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph of Neural Network\n",
    "\n",
    "Constructing a json file with the graph structure of the neural network (nodes and links). This part is for direct visualization of the static neural network structure with weights. Not used to calculate the node values interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "links = []\n",
    "# iterate through the layers to get links and nodes\n",
    "for layerNum in np.arange(0, len(wts), 2):\n",
    "    m, n = wts[layerNum].shape\n",
    "    for i in range(m):\n",
    "        node_id = int(layerNum/2*MaxSize + i)\n",
    "        nodes.append({'id':node_id, 'LayerNum':int(layerNum/2), 'NodeNum':i})\n",
    "        for j in range(n):\n",
    "            source = node_id\n",
    "            target = int((layerNum/2+1)*MaxSize + j)\n",
    "            links.append({'source':source, 'target':target, 'weight':float(wts[layerNum][i,j])})\n",
    "# output layer nodes\n",
    "for l in range(len(wts[-1])):\n",
    "    node_id = int(len(wts)/2*MaxSize + l)\n",
    "    nodes.append({'id':node_id, 'LayerNum':int(len(wts)/2), 'NodeNum':i})\n",
    "# Build the network graph\n",
    "Graph = {'nodes': nodes, 'links': links}\n",
    "with open('NetworkGraph'+name+'.json', 'w') as fp:\n",
    "    json.dump(Graph, fp)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Tensors in Json\n",
    "\n",
    "Import the weights and biases to json. This is the main data structure used in the interactive visualization. The neural network graph and node computation are done in the code in JavaScript after importing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights = []\n",
    "Bias = []\n",
    "for l in np.arange(0, len(wts), 2):\n",
    "    W = []\n",
    "    for i in range(wts[l].shape[0]):\n",
    "        w = []\n",
    "        for j in range(wts[l].shape[1]):\n",
    "            w.append(float(wts[l][i,j]))\n",
    "        W.append(w)\n",
    "    Weights.append(W)\n",
    "    b = []\n",
    "    for i in range(len(wts[l+1])):\n",
    "        b.append(float(wts[l+1][i]))\n",
    "    Bias.append(b)\n",
    "FeedforwardNN = {'weights': Weights, 'bias': Bias, 'WidthLimit': MaxSize}\n",
    "with open('FeedforwardNN'+name+'.json', 'w') as fp:\n",
    "    json.dump(FeedforwardNN, fp)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
